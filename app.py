# -*- coding: utf-8 -*-
"""AI_hospital_traige.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14zUn2YEY1QbQSeO_t6KMC0jdeBM6Jzsg
"""

from google.colab import drive
drive.mount('add your drive link')

import os
os.listdir('add drive link to project folder')

!pip install pandas numpy tqdm nltk sentence-transformers pypdf

import nltk
nltk.download('punkt')

import pandas as pd

patients = pd.read_csv(
    'PATIENTS.csv'
)

patients.head()

patients = patients[['SUBJECT_ID', 'GENDER', 'DOB']]
patients.dropna(inplace=True)

patients['DOB'] = pd.to_datetime(patients['DOB'])

patients.to_csv(
    'processed/patients_clean.csv',
    index=False
)

admissions = pd.read_csv(
    'data/ADMISSIONS.csv'
)

admissions = admissions[
    ['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'ADMISSION_TYPE']
]

admissions['ADMITTIME'] = pd.to_datetime(admissions['ADMITTIME'])

admissions = admissions[admissions['ADMISSION_TYPE'] != 'ELECTIVE']

admissions.to_csv(
    'processed/mimic_clean/admissions_clean.csv',
    index=False
)

notes = pd.read_csv(
    'data//NOTEEVENTS.csv'
)

notes.head()

notes = pd.read_csv(
    'data/NOTEEVENTS.csv',
    usecols=['SUBJECT_ID', 'HADM_ID', 'CHARTTIME', 'CATEGORY', 'TEXT'],
    low_memory=False
)

keep_categories = [
    'Emergency Department',
    'Physician',
    'Nursing'
]

notes = notes[notes['CATEGORY'].isin(keep_categories)]
notes.dropna(subset=['TEXT'], inplace=True)

notes = notes[~notes['TEXT'].str.lower().str.contains('discharge summary')]

notes.to_csv(
    'processed/mimic_clean/notes_clean.csv',
    index=False
)

patients = pd.read_csv('processed/mimic_clean/patients_clean.csv')
admissions = pd.read_csv('processed/mimic_clean/admissions_clean.csv')
notes = pd.read_csv('processed/mimic_clean/notes_clean.csv')

merged = admissions.merge(patients, on='SUBJECT_ID', how='left')

merged = merged.merge(notes, on=['SUBJECT_ID', 'HADM_ID'], how='inner')

def build_triage_input(row):
    return f"""
    Age: UNKNOWN
    Gender: {row['GENDER']}
    Symptoms / Observations:
    {row['TEXT']}
    """

merged['triage_input'] = merged.apply(build_triage_input, axis=1)

merged[['SUBJECT_ID', 'HADM_ID', 'triage_input']].to_csv(
    'processed/mimic_clean/triage_inputs.csv',
    index=False
)

from pypdf import PdfReader
from tqdm import tqdm

pdf_dir = 'data/guidelines/'
out_dir = 'processed/pdf_chunks/'

def extract_text(pdf_path):
    reader = PdfReader(pdf_path)
    text = ""
    for page in reader.pages:
        text += page.extract_text() + "\n"
    return text

from nltk.tokenize import sent_tokenize

def chunk_text(text, chunk_size=400):
    sentences = sent_tokenize(text)
    chunks, current = [], ""

    for s in sentences:
        if len(current) + len(s) < chunk_size:
            current += " " + s
        else:
            chunks.append(current.strip())
            current = s
    chunks.append(current.strip())
    return chunks

import nltk

nltk.download('punkt')
nltk.download('punkt_tab')

import os
all_chunks = []

for pdf in tqdm(os.listdir(pdf_dir)):
    text = extract_text(pdf_dir + pdf)
    chunks = chunk_text(text)

    for c in chunks:
        all_chunks.append({
            "text": c,
            "source": pdf
        })

pd.DataFrame(all_chunks).to_csv(
    'processed/pdf_chunks/guideline_chunks.csv',
    index=False
)

!pip install -q \
pandas numpy tqdm \
pdfplumber \
nltk \
scikit-learn \
faiss-cpu \
sentence-transformers \
gradio

import pandas as pd
import numpy as np
from tqdm import tqdm
import pdfplumber
import nltk
from sentence_transformers import SentenceTransformer
import faiss

nltk.download('punkt')
nltk.download('punkt_tab')

import os

base_dir = "/content/triage_ai"

folders = [

    "vector_store",
    "agents",
    "app"
]

for f in folders:
    os.makedirs(os.path.join(base_dir, f), exist_ok=True)

print("Folder structure created ‚úÖ")

import pandas as pd

base_dir = "AI_Triage_Project/data"

patients = pd.read_csv(f"{base_dir}/PATIENTS.csv")
admissions = pd.read_csv(f"{base_dir}/ADMISSIONS.csv")
notes = pd.read_csv(f"{base_dir}/NOTEEVENTS.csv")

patients.head()

admissions.head()

notes.head()

print("Patients:", patients.shape)
print("Admissions:", admissions.shape)
print("Notes:", notes.shape)

notes = pd.read_csv(
    "AI_Triage_Project/data/NOTEEVENTS.csv",
    low_memory=False
)

print(notes.shape)

notes['CATEGORY'].value_counts().head(15)

triage_notes = notes[
    notes['CATEGORY'].isin([
        "Nursing/other",
        "Physician",
        "Discharge summary",
        "Nursing"
    ])
].copy()

print("Filtered notes:", triage_notes.shape)

triage_notes[['CATEGORY', 'TEXT']].sample(10, random_state=42)

merged = triage_notes.merge(
    patients[['SUBJECT_ID', 'GENDER', 'DOB']],
    on='SUBJECT_ID',
    how='left'
)

import pandas as pd
import numpy as np
from datetime import datetime

merged['DOB'] = pd.to_datetime(merged['DOB'], errors='coerce')
merged['CHARTTIME'] = pd.to_datetime(merged['CHARTTIME'], errors='coerce')

merged.loc[(merged['DOB'].dt.year < 1900) | (merged['DOB'].dt.year > 2100), 'DOB'] = pd.NaT
merged.loc[(merged['CHARTTIME'].dt.year < 1900) | (merged['CHARTTIME'].dt.year > 2100), 'CHARTTIME'] = pd.NaT

merged['DOB_py'] = merged['DOB'].apply(lambda x: x.to_pydatetime() if pd.notna(x) else None)
merged['CHARTTIME_py'] = merged['CHARTTIME'].apply(lambda x: x.to_pydatetime() if pd.notna(x) else None)

def safe_compute_age(dob, chart):
    try:
        if dob is None or chart is None:
            return np.nan
        if chart < dob:
            return np.nan
        delta = chart - dob
        return delta.days / 365.25
    except Exception:
        return np.nan

merged['AGE'] = merged.apply(lambda row: safe_compute_age(row['DOB_py'], row['CHARTTIME_py']), axis=1)

merged['AGE'] = merged['AGE'].clip(upper=120)

print(merged[['AGE', 'GENDER']].head(10))
print("Number of valid AGE entries:", merged['AGE'].count())

import re

def clean_text(text):
    if pd.isna(text):
        return ""
    text = re.sub(r'\[\*\*.*?\*\*\]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

merged['CLEAN_TEXT'] = merged['TEXT'].apply(clean_text)
merged[['CATEGORY', 'CLEAN_TEXT']].sample(5, random_state=42)

def remove_diagnosis(text):
    text = re.sub(r'\bICD-?\d+\b', '', text, flags=re.IGNORECASE)
    return text

merged['CLEAN_TEXT'] = merged['CLEAN_TEXT'].apply(remove_diagnosis)

merged['TEXT_LENGTH'] = merged['CLEAN_TEXT'].apply(len)
merged = merged[merged['TEXT_LENGTH'] > 20]
merged.shape

def age_group(age):
    if pd.isna(age):
        return "Unknown"
    elif age < 18:
        return "Child"
    elif age < 65:
        return "Adult"
    else:
        return "Senior"

merged['AGE_GROUP'] = merged['AGE'].apply(age_group)
merged[['AGE', 'AGE_GROUP', 'GENDER', 'CLEAN_TEXT']].head(5)

merged.sample(5, random_state=42)[['AGE_GROUP', 'GENDER', 'CATEGORY', 'CLEAN_TEXT']]

def age_group(age):
    if pd.isna(age):
        return "Unknown"
    elif age < 1:
        return "Infant"
    elif age < 12:
        return "Child"
    elif age < 18:
        return "Teen"
    elif age < 60:
        return "Adult"
    else:
        return "Senior"

merged['AGE_GROUP'] = merged['AGE'].apply(age_group)
merged[['AGE', 'AGE_GROUP']].sample(5, random_state=42)

import re

def clean_text(text):
    if pd.isna(text):
        return ""

    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r"[^a-zA-Z0-9.,!?'-]", ' ', text)

    text = text.lower().strip()

    return text

merged['CLEAN_TEXT'] = merged['TEXT'].apply(clean_text)
merged[['CATEGORY', 'CLEAN_TEXT']].sample(5, random_state=42)

symptom_keywords = ['fever', 'pain', 'cough', 'breath', 'confusion', 'trauma', 'bleeding', 'vomit']

def extract_symptoms(text):
    present = []
    for kw in symptom_keywords:
        if kw in text:
            present.append(kw)
    return present

merged['SYMPTOMS'] = merged['CLEAN_TEXT'].apply(extract_symptoms)
merged[['CLEAN_TEXT', 'SYMPTOMS']].sample(5, random_state=42)

merged[['AGE_GROUP', 'GENDER', 'CATEGORY', 'CLEAN_TEXT', 'SYMPTOMS']].sample(5, random_state=42)

def urgency_score(row):
    symptoms = row['SYMPTOMS']
    age_group = row['AGE_GROUP']

    score = 1

    high_urgency = ['breath', 'confusion', 'trauma', 'bleeding']
    medium_urgency = ['fever', 'pain', 'vomit', 'cough']

    if any(s in symptoms for s in high_urgency):
        score = 3
    elif any(s in symptoms for s in medium_urgency):
        score = 2

    if age_group in ['Infant', 'Senior'] and score < 3:
        score += 1

    return score

merged['URGENCY_SCORE'] = merged.apply(urgency_score, axis=1)
merged[['AGE_GROUP', 'SYMPTOMS', 'URGENCY_SCORE']].sample(10, random_state=42)

merged['URGENCY_SCORE'].value_counts()

score_map = {1: "Low", 2: "Medium", 3: "High"}
merged['URGENCY_LABEL'] = merged['URGENCY_SCORE'].map(score_map)
merged[['SYMPTOMS', 'URGENCY_SCORE', 'URGENCY_LABEL']].sample(5, random_state=42)

!pip install PyPDF2

from pathlib import Path
from PyPDF2 import PdfReader

guideline_dir = "AI_Triage_Project/data/guidelines/"
pdf_files = list(Path(guideline_dir).glob("*.pdf"))

guidelines = {}
for pdf_path in pdf_files:
    reader = PdfReader(str(pdf_path))
    text = ""
    for page in reader.pages:
        text += page.extract_text() + "\n"
    guidelines[pdf_path.stem] = text[:10000]

def match_guideline(symptoms):
    matches = []
    for symptom in symptoms:
        for name, text in guidelines.items():
            if symptom.lower() in text.lower():
                matches.append(name)
    return matches

merged['MATCHED_GUIDELINES'] = merged['SYMPTOMS'].apply(match_guideline)
merged[['SYMPTOMS', 'MATCHED_GUIDELINES']].sample(5, random_state=42)

def escalation_decision(urgency_label):
    if urgency_label == "High":
        return "Immediate Doctor Referral"
    elif urgency_label == "Medium":
        return "Doctor Soon"
    elif urgency_label == "Low":
        return "Regular Monitoring"
    else:
        return "No Action"

merged['ESCALATION'] = merged['URGENCY_LABEL'].apply(escalation_decision)

merged[['AGE_GROUP', 'GENDER', 'CATEGORY', 'SYMPTOMS', 'URGENCY_LABEL', 'ESCALATION']].sample(10, random_state=42)

!pip install -q \
    openai-whisper \
    moviepy \
    transformers \
    torch \
    accelerate \
    scikit-learn \
    pandas \
    gradio \
    faiss-cpu

import re
import os
import pickle
from typing import List, Dict, Tuple

import pandas as pd
import numpy as np

import whisper
from moviepy.editor import VideoFileClip
from transformers import pipeline

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression

import faiss
import gradio as gr

CONFIG = {
    "WHISPER_MODEL": "small",      # CPU-safe
    "NER_MODEL": "d4data/biomedical-ner-all",
    "LANGUAGE": "en",
    "MAX_GUIDELINES": 3
}

"""
DATA CONTRACTS (DO NOT VIOLATE)

Raw input:
    - text: str
    - audio_path: str
    - video_path: str

Clean text:
    - str

Symptoms:
    - List[str]  (canonical only)

Urgency:
    - score: int (0,1,2)
    - label: str ("Low","Medium","High")

Guidelines:
    - List[str]

Escalation:
    - str
"""

whisper_model = whisper.load_model(CONFIG["WHISPER_MODEL"])

print("‚úÖ Whisper model loaded")

def extract_audio_from_video(video_path: str, audio_path: str = "temp_audio.wav") -> str:
    """
    Extract audio from video file.
    Returns path to extracted audio.
    """
    if not os.path.exists(video_path):
        raise FileNotFoundError("Video file not found")

    clip = VideoFileClip(video_path)
    clip.audio.write_audiofile(audio_path, verbose=False, logger=None)
    clip.close()

    return audio_path

def transcribe_audio(audio_path: str) -> str:
    """
    Convert audio file to text using Whisper.
    """
    if not os.path.exists(audio_path):
        raise FileNotFoundError("Audio file not found")

    result = whisper_model.transcribe(audio_path)
    return result["text"]

def clean_text(text: str) -> str:
    """
    Normalize text for medical NLP.
    """
    text = text.lower()
    text = text.strip()
    text = re.sub(r"\s+", " ", text)
    text = re.sub(r"[^a-z0-9\s]", "", text)
    return text

def process_user_input(
    text: str = None,
    audio_path: str = None,
    video_path: str = None
) -> str:
    """
    Converts text/audio/video into CLEAN TEXT.
    Priority:
    video ‚Üí audio ‚Üí text
    """

    if video_path:
        audio_path = extract_audio_from_video(video_path)

    if audio_path:
        text = transcribe_audio(audio_path)

    if not text:
        return ""

    return clean_text(text)

# TEXT
print(process_user_input(text="Patient reports DYSPNEA and Chest Pain!!"))

# AUDIO (if you have a file)
# print(process_user_input(audio_path="sample.wav"))

# VIDEO (if you have a file)
# print(process_user_input(video_path="sample.mp4"))

from transformers import pipeline

medical_ner = pipeline(
    "ner",
    model="d4data/biomedical-ner-all",
    aggregation_strategy="simple",
    device=-1   # force CPU
)

print("‚úÖ Medical NER loaded")

CANONICAL_SYMPTOMS = {
    "breath",
    "pain",
    "fever",
    "vomit",
    "cough",
    "headache"
}

SYMPTOM_PHRASES = [
    # üî¥ Breathing (highest risk)
    ("shortness of breath", "breath"),
    ("difficulty breathing", "breath"),
    ("trouble breathing", "breath"),
    ("respiratory distress", "breath"),
    ("dyspnea", "breath"),

    # üî¥ Pain
    ("severe chest pain", "pain"),
    ("chest pain", "pain"),
    ("abdominal pain", "pain"),
    ("severe pain", "pain"),
    ("acute pain", "pain"),
    ("pain", "pain"),

    # üü† Fever
    ("high temperature", "fever"),
    ("fever", "fever"),

    # üü† Vomiting
    ("vomiting", "vomit"),
    ("vomit", "vomit"),
    ("emesis", "vomit"),
    ("nausea", "vomit"),

    # üü° Cough
    ("persistent cough", "cough"),
    ("dry cough", "cough"),
    ("cough", "cough"),

    # üü° Headache
    ("severe headache", "headache"),
    ("headache", "headache"),
]

def extract_symptoms(text: str) -> list:
    """
    Medical-safe symptom extraction.
    Rule-first, NER-supported, canonical-only.
    """

    text = text.lower()
    detected = set()

    for phrase, canonical in SYMPTOM_PHRASES:
        if phrase in text:
            detected.add(canonical)

    try:
        entities = medical_ner(text)
        for ent in entities:
            if ent["entity_group"] in ["Sign_symptom", "Disease_disorder"]:
                ent_text = ent["word"].lower()
                for phrase, canonical in SYMPTOM_PHRASES:
                    if phrase in ent_text:
                        detected.add(canonical)
    except Exception:
        pass


    return sorted(list(detected & CANONICAL_SYMPTOMS))

tests = [
    "Patient reports dyspnea and severe chest pain.",
    "Difficulty breathing with fever and cough",
    "Severe abdominal pain and vomiting",
    "Persistent cough and headache",
    "Chest pain but no breathing issues"
]

for t in tests:
    print(t, "‚Üí", extract_symptoms(t))

HIGH_RISK_SYMPTOMS = {"breath", "pain"}

MEDIUM_RISK_SYMPTOMS = {"fever", "vomit", "cough", "headache"}

from typing import List, Tuple

def compute_urgency(symptoms: List[str], age_group="Unknown", gender="Unknown") -> Tuple[int, str]:
    """
    Compute urgency score and label.

    Args:
        symptoms: List of canonical symptoms
        age_group: "Adult", "Elderly", etc.
        gender: "M", "F", or "Unknown"

    Returns:
        score: 1=Low, 2=Medium, 3=High
        label: "Low", "Medium", "High"
    """

    if not symptoms:
        return 1, "Low"

    score, label = 1, "Low"

    if any(s in HIGH_RISK_SYMPTOMS for s in symptoms):
        score, label = 3, "High"
    elif any(s in MEDIUM_RISK_SYMPTOMS for s in symptoms):
        score, label = 2, "Medium"

    if age_group == "Elderly" and label != "High":
        score = min(score + 1, 3)
        label = "High" if score == 3 else "Medium"

    return score, label

test_cases = [
    (["breath", "pain"], "Adult"),
    (["fever", "cough"], "Adult"),
    (["vomit"], "Elderly"),
    ([], "Adult"),
]

for symptoms, age in test_cases:
    score, label = compute_urgency(symptoms, age)
    print(f"Symptoms: {symptoms}, Age: {age} ‚Üí Score: {score}, Label: {label}")

GUIDELINES_DB = {
    "breath": [
        "WHO ‚Äì IITT: Respiratory distress guidance",
        "Ensure airway patency and oxygen monitoring"
    ],
    "pain": [
        "WHO ‚Äì Pain Management Guidelines",
        "Consider analgesics based on severity"
    ],
    "fever": [
        "WHO ‚Äì Fever Management Guidelines",
        "Check for underlying infection and hydration"
    ],
    "vomit": [
        "WHO ‚Äì Gastrointestinal Guidelines",
        "Monitor for dehydration and electrolytes"
    ],
    "cough": [
        "WHO ‚Äì Respiratory Infection Guidelines",
        "Assess for infection and supportive care"
    ],
    "headache": [
        "WHO ‚Äì Neurological Assessment Guidelines",
        "Assess for red flags: vision changes, vomiting, fever"
    ]
}

from typing import List

def retrieve_guidelines(symptoms: List[str], urgency_label=None, age_group="Unknown", gender="Unknown") -> List[str]:
    """
    Retrieve guideline snippets for given symptoms.

    Args:
        symptoms: list of canonical symptoms
        urgency_label: High / Medium / Low (optional)
        age_group: Adult / Elderly / Unknown
        gender: M / F / Unknown

    Returns:
        List of relevant guidelines (deduplicated)
    """
    guidelines = []

    for symptom in symptoms:
        if symptom in GUIDELINES_DB:
            guidelines.extend(GUIDELINES_DB[symptom])

    if age_group == "Elderly" and "breath" in symptoms:
        guidelines.append("Elderly patients with respiratory distress should be prioritized for ICU monitoring")

    return list(set(guidelines))

test_symptoms_list = [
    ["breath", "pain"],
    ["fever", "cough"],
    ["headache"],
    []
]

for symptoms in test_symptoms_list:
    guides = retrieve_guidelines(symptoms, age_group="Elderly")
    print(f"Symptoms: {symptoms} ‚Üí Guidelines: {guides}\n")

def escalation_decision(symptoms: list, urgency_label: str, age_group="Unknown") -> str:
    """
    Determine escalation based on symptoms and urgency.

    Args:
        symptoms: list of canonical symptoms
        urgency_label: High / Medium / Low
        age_group: Adult / Elderly / Unknown

    Returns:
        Escalation recommendation (string)
    """
    if "breath" in symptoms:
        return "Immediate Doctor Referral"

    if urgency_label == "High":
        return "Immediate Doctor Referral"
    elif urgency_label == "Medium":
        return "Doctor Soon"
    else:
        return "Regular Monitoring"

import pandas as pd

feedback_log = pd.DataFrame(columns=[
    "CLEAN_TEXT", "SYMPTOMS", "URGENCY_LABEL",
    "GUIDELINES", "ESCALATION", "USER_FEEDBACK"
])

def log_feedback(triage_result: dict, user_feedback: str):
    """
    Log user feedback to improve triage system over time.
    """
    global feedback_log
    record = pd.DataFrame([{
        "CLEAN_TEXT": triage_result.get("CLEAN_TEXT", ""),
        "SYMPTOMS": triage_result.get("SYMPTOMS", []),
        "URGENCY_LABEL": triage_result.get("URGENCY_LABEL", ""),
        "GUIDELINES": triage_result.get("GUIDELINES", []),
        "ESCALATION": triage_result.get("ESCALATION", ""),
        "USER_FEEDBACK": user_feedback
    }])
    feedback_log = pd.concat([feedback_log, record], ignore_index=True)

def summarize_feedback():
    """
    Summarize feedback collected so far.
    """
    if feedback_log.empty:
        print("No feedback yet.")
        return
    summary = feedback_log["USER_FEEDBACK"].value_counts()
    print("Feedback Summary:\n", summary)

triage_example = {
    "CLEAN_TEXT": "Patient reports dyspnea and severe chest pain",
    "SYMPTOMS": ["breath", "pain"],
    "URGENCY_LABEL": "High",
    "GUIDELINES": retrieve_guidelines(["breath", "pain"]),
    "ESCALATION": escalation_decision(["breath", "pain"], "High", "Adult")
}

print(triage_example)

user_feedback = "Correct"
log_feedback(triage_example, user_feedback)

summarize_feedback()

import pandas as pd
import os

FEEDBACK_FILE = "feedback_log.csv"

if os.path.exists(FEEDBACK_FILE):
    feedback_log = pd.read_csv(FEEDBACK_FILE)
else:
    feedback_log = pd.DataFrame(columns=[
        "CLEAN_TEXT", "SYMPTOMS", "URGENCY_LABEL",
        "GUIDELINES", "ESCALATION", "USER_FEEDBACK"
    ])

def log_feedback(result_dict, user_feedback):
    global feedback_log
    record = pd.DataFrame([{
        "CLEAN_TEXT": result_dict.get("CLEAN_TEXT", ""),
        "SYMPTOMS": ", ".join(result_dict.get("SYMPTOMS", [])),
        "URGENCY_LABEL": result_dict.get("URGENCY_LABEL", ""),
        "GUIDELINES": ", ".join(result_dict.get("GUIDELINES", [])),
        "ESCALATION": result_dict.get("ESCALATION", ""),
        "USER_FEEDBACK": user_feedback
    }])
    feedback_log = pd.concat([feedback_log, record], ignore_index=True)
    feedback_log.to_csv(FEEDBACK_FILE, index=False)

def summarize_feedback():
    if feedback_log.empty:
        return "No feedback yet."
    summary = feedback_log["USER_FEEDBACK"].value_counts()
    return summary.to_dict()

def adjust_urgency_rules():
    """
    Simulate learning by checking which symptoms are often marked 'Incorrect'
    and increasing their urgency level in rules.
    """
    if feedback_log.empty:
        return
    incorrect_logs = feedback_log[feedback_log["USER_FEEDBACK"] == "Incorrect"]
    symptom_counts = {}
    for row in incorrect_logs["SYMPTOMS"]:
        for s in row.split(", "):
            symptom_counts[s] = symptom_counts.get(s, 0) + 1
    for s, count in symptom_counts.items():
        if count >= 3 and s not in {"breath", "pain"}:
            print(f"‚ö†Ô∏è Learning: Promoting symptom '{s}' to HIGH risk due to repeated feedback")

SYMPTOM_WEIGHTS = {
    "breath": 3,
    "pain": 3,
    "fever": 2,
    "vomit": 2,
    "cough": 2,
    "headache": 1  # Low-risk
}

LEARNING_RATE = 0.1


def compute_urgency_dynamic(symptoms, age_group="Unknown"):
    """
    Compute urgency based on dynamic symptom weights
    """
    if not symptoms:
        return 1, "Low"

    score = sum(SYMPTOM_WEIGHTS.get(s, 1) for s in symptoms)

    if score >= 5:
        label = "High"
    elif score >= 3:
        label = "Medium"
    else:
        label = "Low"

    if age_group == "Elderly" and label != "High":
        label = "High" if score >= 4 else "Medium"

    return score, label


def update_weights_based_on_feedback(symptoms, urgency_label, feedback):
    """
    Adjust SYMPTOM_WEIGHTS based on user feedback
    """
    global SYMPTOM_WEIGHTS

    if feedback == "Correct":
        for s in symptoms:
            SYMPTOM_WEIGHTS[s] = min(SYMPTOM_WEIGHTS.get(s, 1) + LEARNING_RATE, 5)
    elif feedback in ["Incorrect", "Needs Review"]:
        for s in symptoms:
            SYMPTOM_WEIGHTS[s] = max(SYMPTOM_WEIGHTS.get(s, 1) - LEARNING_RATE, 1)

import gradio as gr

def triage_with_feedback(text_input, audio_input, video_input, age_group, gender, user_feedback):
    clean_text_input, symptoms = process_input(text_input, audio_input, video_input)

    urgency_score, urgency_label = compute_urgency_dynamic(symptoms, age_group)

    guidelines = retrieve_guidelines(symptoms)

    escalation = escalation_decision(symptoms, urgency_label, age_group)

    if user_feedback:
        log_feedback({
            "CLEAN_TEXT": clean_text_input,
            "SYMPTOMS": symptoms,
            "URGENCY_LABEL": urgency_label,
            "GUIDELINES": guidelines,
            "ESCALATION": escalation
        }, user_feedback)

        update_weights_based_on_feedback(symptoms, urgency_label, user_feedback)

    output = f"""
‚úÖ CLEAN TEXT: {clean_text_input}
‚úÖ SYMPTOMS: {symptoms}
‚úÖ URGENCY: {urgency_label}
‚úÖ GUIDELINES: {guidelines}
‚úÖ ESCALATION: {escalation}

üìù Feedback Summary:
{get_feedback_summary()}

üìä Current Symptom Weights:
{SYMPTOM_WEIGHTS}
"""
    return output

with gr.Blocks() as demo:
    gr.Markdown("## üè• Medical Triage System (CPU-only, Explainable, Feedback-enabled)")

    with gr.Row():
        with gr.Column():
            text_input = gr.Textbox(label="Patient Text Input", placeholder="Enter patient symptoms...")
            audio_input = gr.Audio(label="Upload Audio (optional)", type="filepath")
            video_input = gr.Video(label="Upload Video (optional)")
            age_input = gr.Dropdown(choices=["Adult", "Elderly", "Child"], label="Age Group", value="Adult")
            gender_input = gr.Dropdown(choices=["Unknown", "M", "F"], label="Gender", value="Unknown")
            feedback_input = gr.Dropdown(
                choices=["", "Correct", "Incorrect", "Needs Review"],
                label="Your Feedback",
                value=""
            )
            submit_btn = gr.Button("Run Triage")

        with gr.Column():
            output_text = gr.Textbox(label="Triage Results + Feedback Summary", lines=20)

    submit_btn.click(
        fn=triage_with_feedback,
        inputs=[text_input, audio_input, video_input, age_input, gender_input, feedback_input],
        outputs=output_text
    )

demo.launch()

